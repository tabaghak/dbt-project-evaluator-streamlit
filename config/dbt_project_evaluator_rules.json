{
  "Modeling": {
    "rules": {
      "fct_direct_join_to_source": {
        "name": "Direct Join to Source",
        "description": "Those `staging` models are then the ones read from by the other downstream models.",
        "example": "`int_model_4` is pulling in both a model and a source.\n\n![DAG showing a model and a source joining into a new model](images/fct_direct_join_to_source_DAG_showing_a_model_and_a_sour.png){ width=500 }",
        "exception": "Not specified in documentation",
        "reason_to_flag": "We highly recommend having a one-to-one relationship between sources and their corresponding `staging` model, and not having any other model reading from the source. Those `staging` models are then the ones read from by the other downstream models.\n\nThis allows renaming your columns and doing minor transformation on your source data only once and being consistent\nacross all the models that will consume the source data.",
        "remediation": "In our example, we would want to:\n\n1. create a `staging` model for our source data if it doesn't exist already\n2. and join this `staging` model to other ones to create our downstream transformation instead of using the source\n\nAfter refactoring your downstream model to select from the staging layer, your DAG should look like this:\n\n![DAG showing two staging models joining into a new model](images/fct_direct_join_to_source_DAG_showing_two_staging_models.png){ width=500 }"
      },
      "fct_marts_or_intermediate_dependent_on_source": {
        "name": "Downstream Models Dependent on Source",
        "description": "Shows issues related to downstream models dependent on source",
        "example": "`fct_model_9`, a marts model, builds from `source_1.table_5` a source.\n\n![image](images/fct_marts_or_intermediate_dependent_on_source_image.png){ width=500 }",
        "exception": "Not specified in documentation",
        "reason_to_flag": "We very strongly believe that a staging model is the atomic unit of data modeling. Each staging\nmodel bears a one-to-one relationship with the source data table it represents. It has the same\ngranularity, but the columns have been renamed, recast, or usefully reconsidered into a consistent\nformat. With that in mind, if a `marts` or `intermediate` type model joins directly to a `{{ source() }}`\nnode, there likely is a missing model that needs to be added.",
        "remediation": "Add the reference to the appropriate `staging` model to maintain an abstraction layer between your raw data\nand your downstream data artifacts.\n\nAfter refactoring your downstream model to select from the staging layer, your DAG should look like this:\n\n![image](images/fct_marts_or_intermediate_dependent_on_source_image.png){ width=700 }"
      },
      "fct_duplicate_sources": {
        "name": "Duplicate Sources",
        "description": "**How to Remediate**\n\nCombine the duplicate source nodes so that each source database location only has a single source definition in your dbt project.",
        "example": "Imagine you have two separate source nodes - `source_1.table_5` and `source_1.raw_table_5`.\n\n![two source nodes in DAG](images/fct_duplicate_sources_two_source_nodes_in_DAG.png){ width=400 }\n\nBut both source definitions point to the exact same location in your database - `real_database`.`real_schema`.`table_5`.\n\n```yaml\nsources:\n  - name: source_1\n    schema: real_schema\n    database: real_database\n    tables:\n      - name: table_5\n      - name: raw_table_5\n        identifier: table_5\n```",
        "exception": "Not specified in documentation",
        "reason_to_flag": "If you dbt project has multiple source nodes pointing to the exact same location in your data warehouse, you will have an inaccurate view of your lineage.",
        "remediation": "Combine the duplicate source nodes so that each source database location only has a single source definition in your dbt project."
      },
      "fct_hard_coded_references": {
        "name": "Hard Coded References",
        "description": "Direct relation references are determined via regex mapping [here](https://github.",
        "example": "Example not specified in documentation",
        "exception": "Not specified in documentation",
        "reason_to_flag": "Always use the `ref` function when selecting from another model and the `source` function when selecting from raw data, rather than using the direct relation reference (e.g. `my_schema.my_table`). Direct relation references are determined via regex mapping [here](https://github.com/dbt-labs/dbt-project-evaluator/tree/main/macros/find_all_hard_coded_references.sql).\n\nThe `ref` and `source` functions are part of what makes dbt so powerful! Using these functions allows dbt to infer dependencies (and check that you haven't created any circular dependencies), properly generate your DAG, and ensure that models are built in the correct order. This also ensures that your current model selects from upstream tables and views in the same environment that you're working in.",
        "remediation": "Follow dbt best practices to resolve hard coded references issues"
      },
      "fct_model_fanout": {
        "name": "Model Fanout",
        "description": "[See overriding variables section.",
        "example": "`fct_model` has three direct leaf children.\n\n![A DAG showing three models branching out of a fct model](images/fct_model_fanout_A_DAG_showing_three_models_bra.png){ width=500 }",
        "exception": "Some BI tools are better than others at joining and data exploration. For example, with Looker you could\nend your DAG after marts (i.e. fcts & dims) and join those artifacts together (with a little know how\nand setup time) to make your reports. For others, like Tableau, model fanouts might be more\nbeneficial, as this tool prefers big tables over joins, so predefining some reports is usually more performant.\n\nTo exclude specific cases, check out the instructions in [Configuring exceptions to the rules](../customization/exceptions.md).",
        "reason_to_flag": "This might indicate some transformations should move to the BI layer, or a common business transformations\nshould be moved upstream.",
        "remediation": "Queries and transformations can move around between dbt and the BI tool, so how do we try to stay\neffortful in what we decide to put where?\n\nYou can think of dbt as our assembly line which produces expected outputs every time.\n\nYou can think of the BI layer as the place where we take the items produced from our assembly line to\ncustomize them in order to meet our stakeholder's needs.\n\n<!---\nTODO: edit this line in 6 months after more progress is made on the metrics server\n-->\nYour dbt project needs a defined end point! Until the metrics server comes to fruition, you cannot possibly\npredefine every query or quandary your team might have. So decide as a team where that line is and maintain it."
      },
      "fct_multiple_sources_joined": {
        "name": "Multiple Sources Joined",
        "description": "Alternatively, you could keep `stg_model_2` and add\n`base__` models as transitional steps.",
        "example": "`model_1` references two source tables.\n\n![A DAG showing two sources feeding into a staging model](images/fct_multiple_sources_joined_A_DAG_showing_two_sources_feed.png){ width=500 }",
        "exception": "Sometimes companies have a bunch of [identical sources across systems](https://discourse.getdbt.com/t/unioning-identically-structured-data-sources/921). When these identical sources will only ever be used collectively, you should union them once and create a staging layer on the combined result.\n\nTo exclude specific cases, check out the instructions in [Configuring exceptions to the rules](../customization/exceptions.md).",
        "reason_to_flag": "We very strongly believe that a staging model is the atomic unit of data modeling. Each staging\nmodel bears a one-to-one relationship with the source data table it represents. It has the same\ngranularity, but the columns have been renamed, recast, or usefully reconsidered into a consistent\nformat. With that in mind, two `{{ source() }}` declarations in one staging model likely means we are\nnot being composable enough and there are individual building blocks which could be broken out into\ntheir respective models.",
        "remediation": "In this example specifically, those raw sources, `source_1.table_1` and `source_1.table_2` should each\nhave their own staging model (`stg_model_1` and `stg_model_2`), as transitional steps, which will\nthen be combined into a new `int_model_2`. Alternatively, you could keep `stg_model_2` and add\n`base__` models as transitional steps.\n\nTo fix this, try out the [codegen](https://hub.getdbt.com/dbt-labs/codegen/latest/) package! With\nthis package you can dynamically generate the SQL for a staging (what they call base) model, which\nyou will use to populate `stg_model_1` and `stg_model_2` directly from the source data. Create a\nnew model `int_model_2`. Afterwards, within `int_model_2`, update your `{{ source() }}` macros to\n`{{ ref() }}` macros and point them to your newly built staging models. If you had type casting,\nfield aliasing, or other simple improvements made in your original `stg_model_2` SQL, then attempt\nto move that logic back to the new staging models instead. This will help colocate those\ntransformations and avoid duplicate code, so that all downstream models can leverage the same\nset of transformations.\n\nPost-refactor, your DAG should look like this:\n\n![A refactored DAG showing two staging models feeding into an intermediate model](images/fct_multiple_sources_joined_A_refactored_DAG_showing_two_s.png){ width=500 }\n\nor if you want to use base_ models and keep stg_model_2 as is:\n\n![A refactored DAG showing two base models feeding into a staging model](images/fct_multiple_sources_joined_A_refactored_DAG_showing_two_b.png){ width=500 }"
      },
      "fct_rejoining_of_upstream_concepts": {
        "name": "Rejoining of Upstream Concepts",
        "description": "`int_model_4` has no other downstream dependencies other than `int_model_5`.",
        "example": "`stg_model_1`, `int_model_4`, and `int_model_5` create a \"loop\" in the DAG. `int_model_4` has no other downstream dependencies other than `int_model_5`.\n\n<img width=\"500\" alt=\"A DAG showing three resources. A staging model is referenced by both an int model (`int_model_4`) and a second int model (`int_model_5`). `int_model_4` is also being referenced by `int_model_5`. This creates a 'loop' between the staging model, the int model, and the second int model.\" src=\"https://user-images.githubusercontent.com/30663534/159788799-6bfb745b-7316-485e-9665-f7e7f825742c.png\">",
        "exception": "The one major exception to this would be when using a function from\n[dbt_utils](https://hub.getdbt.com/dbt-labs/dbt_utils/latest/) package, such as `star` or `get_column_values`,\n(or similar functions / packages) that require a [relation](https://docs.getdbt.com/reference/dbt-classes#relation)\nas an argument input. If the shape of the data in the output of `stg_model_1` is not the same as what you\nneed for the input to the function within `int_model_5`, then you will indeed need `int_model_4` to create\nthat relation, in which case, leave it.\n\nTo exclude specific cases, check out the instructions in [Configuring exceptions to the rules](../customization/exceptions.md).",
        "reason_to_flag": "This could happen for a variety of reasons: Accidentally duplicating some business concepts in multiple\ndata flows, hesitance to touch (and break) someone else’s model, or perhaps trying to snowflake out\nor modularize everything without awareness of what will help build time.\n\nAs a general rule, snowflaking out models in a thoughtful manner allows for concurrency, but in this\nexample nothing downstream can run until `int_model_4` finishes, so it is not saving any time in\nparallel processing by being its own model. Since both `int_model_4` and `int_model_5` depend solely\non `stg_model_1`, there is likely a better way to write the SQL within one model (`int_model_5`) and\nsimplify the DAG, potentially at the expense of more rows of SQL within the model.",
        "remediation": "Barring jinja/macro/relation exceptions we mention directly above, to resolve this, simply bring the SQL contents from `int_model_4` into a CTE within `int_model_5`, and swap all `{{ ref('int_model_4') }}` references to the new CTE(s).\n\nPost-refactor, your DAG should look like this:\n\n![A refactored DAG removing the 'loop', by folding `int_model_4` into `int_model_5`.](images/fct_rejoining_of_upstream_concepts_A_refactored_DAG_removing_the_.png){ width=500 }"
      },
      "fct_root_models": {
        "name": "Root Models",
        "description": "Each staging model is being referenced by another accompanying model.",
        "example": "`model_4` has no direct parents\n\n![A DAG showing three source tables, each being referenced by a staging model. Each staging model is being referenced by another accompanying model. model_4 is an independent resource not being referenced by any models](images/fct_root_models_A_DAG_showing_three_source_tab.png){ width=500 }",
        "exception": "This behavior may be observed in the case of a manually defined reference table that does not have any dependencies. A good example of this is a `dim_calendar` table that is generated by the `{{ dbt_utils.date_spine() }}` macro — this SQL logic is completely self contained, and does not require any external data sources to execute.\n\nTo exclude specific cases, check out the instructions in [Configuring exceptions to the rules](../customization/exceptions.md).",
        "reason_to_flag": "This pattern violates dbt best practices for root models",
        "remediation": "Start by mapping any table references in the `FROM` clause of the model definition to the models or raw tables that they draw from, and replace those references with the `{{ ref() }}` if the dependency is another dbt model, or the `{{ source() }}` function if the table is a raw data source (this may require the declaration of a new source table). Then, visualize this model in the DAG, and refactor as appropriate according to best practices."
      },
      "fct_source_fanout": {
        "name": "Source Fanout",
        "description": "Shows issues related to source fanout",
        "example": "`source.table_1` has more than one direct child model.\n\n![image](images/fct_source_fanout_image.png){ width=500 }",
        "exception": "NoSQL databases or heavily nested data sources often have so much info json packed into a table\nthat you need to break one raw data source into multiple base models.\n\nTo exclude specific cases, check out the instructions in [Configuring exceptions to the rules](../customization/exceptions.md).",
        "reason_to_flag": "Each source node should be referenced by a single model that performs basic operations, such as renaming, recasting, and other light transformations to maintain consistency through out the project. The role of this staging model is to mirror the raw data but align it with project conventions. The staging model should act as a source of truth and a buffer- any model which depends on the data from a given source should reference the cleaned data in the staging model as opposed to referencing the source directly. This approach keeps the code DRY (any light transformations that need to be done on the raw data are performed only once). Minimizing references to the raw data will also make it easier to update the project should the format of the raw data change.",
        "remediation": "Create a staging model which references the source and cleans the raw data (e.g. renaming, recasting). Any models referencing the source directly should be refactored to point towards the staging model instead.\n\nAfter refactoring the above example, the DAG would look something like this:\n\n![image](images/fct_source_fanout_image.png){ width=500 }"
      },
      "fct_staging_dependent_on_marts_or_intermediate": {
        "name": "Staging Models Dependent on Downstream Models",
        "description": "Shows issues related to staging models dependent on downstream models",
        "example": "`stg_model_5`, a staging model, builds from `fct_model_9` a marts model.\n\n![image](images/fct_staging_dependent_on_marts_or_intermediate_image.png){ width=500 }",
        "exception": "Not specified in documentation",
        "reason_to_flag": "This likely represents a misnamed file. According to dbt best practices, staging models should only\nselect from source nodes. Dependence on downstream models indicates that this model may need to be either\nrenamed, or reconfigured to only select from source nodes.",
        "remediation": "Rename the file in the `child` column to use to appropriate prefix, or change the models lineage\nby pointing the staging model to the appropriate `{{ source() }}`.\n\nAfter updating the model to use the appropriate `{{ source() }}` function, your graph should look like this:\n\n![image](images/fct_staging_dependent_on_marts_or_intermediate_image.png){ width=500 }"
      },
      "fct_staging_dependent_on_staging": {
        "name": "Staging Models Dependent on Other Staging Models",
        "description": "We should move this file to the appropriate intermediate directory and update the file name to `int_model_4`.",
        "example": "`stg_model_2` is a parent of `stg_model_4`.\n\n![A DAG showing stg_model_2 as a parent of stg_model_4.](images/fct_staging_dependent_on_staging_A_DAG_showing_stg_model_2_as_a.png){ width=500 }",
        "exception": "Not specified in documentation",
        "reason_to_flag": "This may indicate a change in naming is necessary, or that the child model should instead reference a source.",
        "remediation": "You should either change the model type of the `child` (maybe to an intermediate or marts model) or change the child's lineage instead reference the appropriate `{{ source() }}`.\n\nIn our example, we might realize that `stg_model_4` is _actually_ an intermediate model. We should move this file to the appropriate intermediate directory and update the file name to `int_model_4`."
      },
      "fct_unused_sources": {
        "name": "Unused Sources",
        "description": "Within the YML file, remove the unused table name, along with descriptions\nor any other nested information.",
        "example": "`source.table_4` isn't being referenced.\n\n![A DAG showing three sources which are each being referenced by an accompanying staging model, and one source that isn't being referenced at all](images/fct_unused_sources_A_DAG_showing_three_sources_wh.png){ width=500 }",
        "exception": "Not specified in documentation",
        "reason_to_flag": "This represents either a source that you have defined in YML but never brought into a model or a\nmodel that was deprecated and the corresponding rows in the source block of the YML file were\nnot deleted at the same time. This simply represents the buildup of cruft in the project that\ndoesn’t need to be there.",
        "remediation": "Navigate to the `sources.yml` file (or whatever your company has called the file) that corresponds\nto the unused source. Within the YML file, remove the unused table name, along with descriptions\nor any other nested information.\n\n  ```yaml title=\"sources.yml\"\n  sources:\n    - name: some_source\n      database: raw\n      tables:\n        - name: table_1\n        - name: table_2\n        - name: table_3\n        - name: table_4  # <-- remove this line\n  ```\n\n![A refactored DAG showing three sources which are each being referenced by an accompanying staging model](images/fct_unused_sources_A_refactored_DAG_showing_three.png){ width=500 }"
      },
      "fct_too_many_joins": {
        "name": "Models with Too Many Joins",
        "description": "[See overriding variables section.",
        "example": "`fct_model_1` directly references seven (7) staging models upstream.\n\n![A DAG showing a model that directly references seven staging models upstream.](images/fct_too_many_joins_A_DAG_showing_a_model_that_dir){ width=600 }",
        "exception": "Not specified in documentation",
        "reason_to_flag": "This likely represents a model in which too much is being done. Having a model that too many upstream models introduces a lot of code complexity, which can be challenging to understand and maintain.",
        "remediation": "Bringing together a reasonable number (typically 4 to 6) of entities or concepts (staging models, or perhaps other intermediate models) that will be joined with another similarly purposed intermediate model to generate a mart. Rather than having too many joins, we can join two intermediate models that each house a piece of the complexity, giving us increased readability, flexibility, testing surface area, and insight into our components.\n\n![A DAG showing a model that directly references only two intermediate models. The intermediate models reference three and four staging models upstream.](images/fct_too_many_joins_A_DAG_showing_a_model_that_dir){ width=700 }"
      }
    }
  },
  "Testing": {
    "rules": {
      "fct_missing_primary_key_tests": {
        "name": "Missing Primary Key Tests",
        "description": "a `dbt_utils.",
        "example": "Example not specified in documentation",
        "exception": "Not specified in documentation",
        "reason_to_flag": "Tests are assertions you make about your models and other resources in your dbt project (e.g. sources, seeds and snapshots). Defining tests is a great way to confirm that your code is working correctly, and helps prevent regressions when your code changes. Models without proper tests on their grain are a risk to the reliability and scalability of your project.",
        "remediation": "Apply a [uniqueness test](https://docs.getdbt.com/reference/resource-properties/tests#unique) and a [not null test](https://docs.getdbt.com/reference/resource-properties/tests#not_null) to the column that represents the grain of your model in its schema entry. For contracted models, optionally replace the not null test with the not null [constraint](https://docs.getdbt.com/reference/resource-properties/constraints). For models that are unique across a combination of columns, we recommend adding a surrogate key column to your model, then applying these tests to that new model. See the [`surrogate_key`](https://github.com/dbt-labs/dbt-utils#surrogate_key-source) macro from dbt_utils for more info! Alternatively, you can use the [`dbt_utils.unique_combination_of_columns`](https://github.com/dbt-labs/dbt-utils#unique_combination_of_columns-source) test from `dbt_utils`. Check out the [overriding variables section](../customization/overriding-variables.md) to read more about configuring other primary key tests for your project!\n\nAdditional tests can be configured by applying a [generic test](https://docs.getdbt.com/docs/building-a-dbt-project/tests#generic-tests) in the model's `.yml` entry or by creating a [singular test](https://docs.getdbt.com/docs/building-a-dbt-project/tests#singular-tests)\nin the `tests` directory of you project."
      },
      "fct_sources_without_freshness": {
        "name": "Missing Source Freshness",
        "description": "Shows issues related to missing source freshness",
        "example": "Example not specified in documentation",
        "exception": "Not specified in documentation",
        "reason_to_flag": "Source freshness is useful for understanding if your data pipelines are in a healthy state and is a critical component of defining SLAs for your warehouse. Enabling freshness for sources also facilitates [referencing the source freshness results in the selectors](https://docs.getdbt.com/reference/node-selection/methods#the-source_status-method) for a more efficient execution.",
        "remediation": "Apply a [source freshness block](https://docs.getdbt.com/docs/build/sources#declaring-source-freshness) to the source definition. This can be implemented at either the source name or table name level."
      },
      "fct_test_coverage": {
        "name": "Test Coverage",
        "description": "`<model_type>_test_coverage_pct`: the percentage of each of your model types that have minimum 1 test applied.",
        "example": "Example not specified in documentation",
        "exception": "Not specified in documentation",
        "reason_to_flag": "This pattern violates dbt best practices for test coverage",
        "remediation": "Apply a [generic test](https://docs.getdbt.com/docs/building-a-dbt-project/tests#generic-tests) in the model's `.yml` entry, or create a [singular test](https://docs.getdbt.com/docs/building-a-dbt-project/tests#singular-tests)\nin the `tests` directory of you project.\n\nAs explained above, we recommend [at a minimum](https://www.getdbt.com/analytics-engineering/transformation/data-testing/#what-should-you-test), every model should have `not_null` and `unique` tests set up on a primary key."
      }
    }
  },
  "Structure": {
    "rules": {
      "fct_model_naming_conventions": {
        "name": "Model Naming Conventions",
        "description": "Shows issues related to model naming conventions",
        "example": "Consider `model_8` which is nested in the `marts` subdirectory:\n\n```bash\n├── dbt_project.yml\n└── models\n    ├── marts\n        └── model_8.sql\n```\n\nThis model should be renamed to either `fct_model_8` or `dim_model_8`.",
        "exception": "Not specified in documentation",
        "reason_to_flag": "Without appropriate naming conventions, a user querying the data warehouse might incorrectly assume the model type of a given relation. In order to explicitly name\nthe model type in the data warehouse, we recommend appropriately prefixing your models in dbt.\n\n| Model Type   | Appropriate Prefixes |\n| ------------ | -------------------- |\n| Staging      | `stg_`               |\n| Intermediate | `int_`               |\n| Marts        | `fct_` or `dim_`     |\n| Other        | `rpt_`               |",
        "remediation": "For each model flagged, ensure the model type is defined and the model name is prefixed appropriately."
      },
      "fct_model_directories": {
        "name": "Model Directories",
        "description": "Shows issues related to model directories",
        "example": "Consider `stg_model_3` which is a staging model for `source_2.table_3`:\n\n![A DAG showing source_2.table_3 as a parent of stg_model_3](images/fct_model_directories_A_DAG_showing_source_2_table_3.png){ width=500 }\n\nBut, `stg_model_3.sql` is inappropriately nested in the subdirectory `source_1`:\n\n```bash\n├── dbt_project.yml\n└── models\n    ├── marts\n    └── staging\n        └── source_1\n            ├── stg_model_3.sql\n```\n\nThis file should be moved into the subdirectory `source_2`:\n\n```bash\n├── dbt_project.yml\n└── models\n    ├── marts\n    └── staging\n        ├── source_1\n        └── source_2\n            ├── stg_model_3.sql\n```\n\nConsider `dim_model_7` which is a marts model but is inappropriately nested closest to the subdirectory `intermediate`:\n\n```bash\n├── dbt_project.yml\n└── models\n    └── marts\n        └── intermediate\n            ├── dim_model_7.sql\n```\n\nThis file should be moved closest to the subdirectory `marts`:\n\n```bash\n├── dbt_project.yml\n└── models\n    └── marts\n        ├── dim_model_7.sql\n```\n\nConsider `int_model_4` which is an intermediate model but is inappropriately nested closest to the subdirectory `marts`:\n\n```bash\n├── dbt_project.yml\n└── models\n    └── marts\n        ├── int_model_4.sql\n```\n\nThis file should be moved closest to the subdirectory `intermediate`:\n\n```bash\n├── dbt_project.yml\n└── models\n    └── marts\n        └── intermediate\n            ├── int_model_4.sql\n```",
        "exception": "Not specified in documentation",
        "reason_to_flag": "Because we often work with multiple data sources, in our staging directory, we create one subdirectory per source.\n\n```bash\n├── dbt_project.yml\n└── models\n    ├── marts\n    └── staging\n        ├── braintree\n        └── stripe\n```\n\nEach staging directory contains:\n\n- One staging model for each raw source table\n- One .yml file which contains source definitions, tests, and documentation (see [Source Directories](#source-directories))\n- One .yml file which contains tests & documentation for models in the same directory (see [Test Directories](#test-directories))\n\nThis provides for clear repository organization, so that analytics engineers can quickly and easily find the information they need.\n\nWe might create additional folders for intermediate models but each file should always be nested closest to the folder name that matches their model type.\n\n```bash\n├── dbt_project.yml\n└── models\n    └── marts\n        └── fct_model_6.sql\n        └── intermediate\n            └── int_model_5.sql\n```",
        "remediation": "For each resource flagged, move the file from the `current_file_path` to `change_file_path_to`."
      },
      "fct_source_directories": {
        "name": "Source Directories",
        "description": "Shows issues related to source directories",
        "example": "Consider `source_2.table_3` which is a `source_2` source but it had been defined inappropriately in a `source.yml` file nested in the subdirectory `source_1`:\n\n```bash\n├── dbt_project.yml\n└── models\n    ├── marts\n    └── staging\n        └── source_1\n            ├── source.yml\n```\n\nThis definition should be moved into a `source.yml` file nested in the subdirectory `source_2`:\n\n```bash\n├── dbt_project.yml\n└── models\n    ├── marts\n    └── staging\n        ├── source_1\n        └── source_2\n            ├── source.yml\n```",
        "exception": "Not specified in documentation",
        "reason_to_flag": "Because we often work with multiple data sources, in our staging directory, we create one subdirectory per source.\n\n```bash\n├── dbt_project.yml\n└── models\n    ├── marts\n    └── staging\n        ├── braintree\n        └── stripe\n```\n\nEach staging directory contains:\n\n- One staging model for each raw source table (see [Model Directories](#source-directories))\n- One .yml file which contains source definitions, tests, and documentation\n- One .yml file which contains tests & documentation for models in the same directory (see [Test Directories](#test-directories))\n\nThis provides for clear repository organization, so that analytics engineers can quickly and easily find the information they need.",
        "remediation": "For each source flagged, move the file from the `current_file_path` to `change_file_path_to`."
      },
      "fct_test_directories": {
        "name": "Test Directories",
        "description": "However, tests for `int_model_4` are configured in `staging/staging.",
        "example": "`int_model_4` is located within `marts/`. However, tests for `int_model_4` are configured in `staging/staging.yml`:\n\n```bash\n├── dbt_project.yml\n└── models\n    └── marts\n        ├── int_model_4.sql\n    └── staging\n        ├── staging.yml\n```\n\nA new yml file should be created in `marts/` which contains all tests and documentation for `int_model_4`, and for the rest of the models in located in the `marts/` directory:\n\n```bash\n├── dbt_project.yml\n└── models\n    └── marts\n        ├── int_model_4.sql\n        ├── marts.yml\n    └── staging\n        ├── staging.yml\n```",
        "exception": "Not specified in documentation",
        "reason_to_flag": "Each subdirectory in `models/` should contain one .yml file that includes the tests and documentation for all models within the given subdirectory. Keeping your repository organized in this way ensures that folks can quickly access the information they need.",
        "remediation": "Move flagged tests from the yml file under `current_test_directory` to the yml file under `change_test_directory_to` (create a new yml file if one does not exist)."
      }
    }
  },
  "Documentation": {
    "rules": {
      "fct_documentation_coverage": {
        "name": "Documentation Coverage",
        "description": "[See overriding variables section.",
        "example": "Example not specified in documentation",
        "exception": "Not specified in documentation",
        "reason_to_flag": "Good documentation for your dbt models will help downstream consumers discover and understand the datasets which you curate for them.\nThe documentation for your project includes model code, a DAG of your project, any tests you've added to a column, and more.",
        "remediation": "Apply a text [description](https://docs.getdbt.com/docs/building-a-dbt-project/documentation#related-documentation) in the model's `.yml` entry, or create a [docs block](https://docs.getdbt.com/docs/building-a-dbt-project/documentation#using-docs-blocks) in a markdown file, and use the `{{ doc() }}`\nfunction in the model's `.yml` entry.\n\n!!! note \"Tip\"\n\n    We recommend that every model in your dbt project has at minimum a model-level description. This ensures that each model's purpose is clear to other developers and stakeholders when viewing the dbt docs site."
      },
      "fct_undocumented_models": {
        "name": "Undocumented Models",
        "description": "Shows issues related to undocumented models",
        "example": "Example not specified in documentation",
        "exception": "Not specified in documentation",
        "reason_to_flag": "Good documentation for your dbt models will help downstream consumers discover and understand the datasets which you curate for them.\nThe documentation for your project includes model code, a DAG of your project, any tests you've added to a column, and more.",
        "remediation": "Apply a text [description](https://docs.getdbt.com/docs/building-a-dbt-project/documentation) in the model's `.yml` entry, or create a [docs block](https://docs.getdbt.com/docs/building-a-dbt-project/documentation#using-docs-blocks) in a markdown file, and use the `{{ doc() }}`\nfunction in the model's `.yml` entry.\n\n!!! note \"Tip\"\n\n    We recommend that every model in your dbt project has at minimum a model-level description. This ensures that each model's purpose is clear to other developers and stakeholders when viewing the dbt docs site. Missing documentation should be addressed first for marts models, then for the rest of your project, to ensure that stakeholders in the organization can understand the data which is surfaced to them."
      },
      "fct_undocumented_source_tables": {
        "name": "Undocumented Source Tables",
        "description": "Shows issues related to undocumented source tables",
        "example": "Example not specified in documentation",
        "exception": "Not specified in documentation",
        "reason_to_flag": "Good documentation for your dbt sources will help contributors to your project understand how and when data is loaded into your warehouse.",
        "remediation": "Apply a text [description](https://docs.getdbt.com/docs/building-a-dbt-project/documentation) in the table's `.yml` entry, or create a [docs block](https://docs.getdbt.com/docs/building-a-dbt-project/documentation#using-docs-blocks) in a markdown file, and use the `{{ doc() }}`\nfunction in the table's `.yml` entry.\n```\nsources:\n  - name: my_source\n    tables:\n      - name: my_table\n        description: This is the source table description\n```"
      },
      "fct_undocumented_sources": {
        "name": "Undocumented Sources",
        "description": "Shows issues related to undocumented sources",
        "example": "Example not specified in documentation",
        "exception": "Not specified in documentation",
        "reason_to_flag": "Good documentation for your dbt sources will help contributors to your project understand how and when data is loaded into your warehouse.",
        "remediation": "Apply a text [description](https://docs.getdbt.com/docs/building-a-dbt-project/documentation) in the source's `.yml` entry, or create a [docs block](https://docs.getdbt.com/docs/building-a-dbt-project/documentation#using-docs-blocks) in a markdown file, and use the `{{ doc() }}`\nfunction in the source's `.yml` entry.\n```\nsources:\n  - name: my_source\n    description: This is the source description\n    tables:\n      - name: my_table\n```"
      }
    }
  },
  "Governance": {
    "rules": {
      "fct_public_models_without_contract": {
        "name": "Public models without contracts",
        "description": "This implies a need for better guarantees around the model's data types and columns.",
        "example": "`report_1` is defined as a public model, but does not have the `contract` configuration to enforce its datatypes.\n\n```yml\n# public model without a contract\nmodels:\n  - name: report_1\n    description: very important OKR reporting model\n    access: public\n\n```",
        "exception": "Not specified in documentation",
        "reason_to_flag": "This pattern violates dbt best practices for public models without contracts",
        "remediation": "Edit the yml to include the contract configuration, as well as a column entry for all columns output by the model, including their datatype. While not strictly required for defining a contracts, it's best practice to also document each column as well.\n\n```yml\nmodels:\n  - name: report_1\n    description: very important OKR reporting model\n    access: public\n    config:\n      contract:\n        enforced: true\n    columns:\n      - name: id \n        data_type: integer\n```"
      },
      "fct_undocumented_public_models": {
        "name": "Undocumented public models",
        "description": "This check is similar to `fct_undocumented_models` ([source](https://github.",
        "example": "`report_1` is defined as a public model, but does not descriptions on the model and each column.\n\n```yml\n# public model without documentation\nmodels:\n  - name: report_1\n    access: public\n    columns:\n      - name: id\n\n```",
        "exception": "Not specified in documentation",
        "reason_to_flag": "Models with public access are free to be consumed by any downstream consumer. This implies a need for higher standards for the model's usability for those cosumers. Adding more documentation can help consumers understand how they should leverage the data from your public model.",
        "remediation": "Edit the yml to include a model level description,  as well as a column entry with a description for all columns output by the model. While not strictly required for public models, these should likely also have contracts added as well. (See [above rule](#public-models-without-contracts))\n\n```yml\nmodels:\n  - name: report_1\n    description: very important OKR reporting model\n    access: public\n    columns:\n      - name: id \n        description: the primary key of my OKR model\n```"
      },
      "fct_exposures_dependent_on_private_models": {
        "name": "Exposures dependent on private models",
        "description": "These tools should read from public, trusted, contracted data sources.",
        "example": "Here's a sample DAG that shows direct exposure relationships.\n\n![An example exposure with a two parents (fct_model_6 and dim_model_7)](images/fct_exposures_dependent_on_private_models_An_example_exposure_with_a_two.png){ width=500 }\n\nIf this were the yml for these two parent models, `dim_model_7` would be flagged by this check, as it is not a public model.\n\n```yml\nmodels:\n  - name: fct_model_6\n    description: very important OKR reporting model\n    access: public\n    config:\n      materialized: table\n      contract:\n        enforced: true\n    columns:\n      - name: id \n        description: the primary key of my OKR model\n        data_type: integer\n  - name: dim_model_7\n    description: excellent model\n    access: private\n```",
        "exception": "Not specified in documentation",
        "reason_to_flag": "Exposures show how and where your data is being consumed in downstream tools. These tools should read from public, trusted, contracted data sources. All models that are exposed to other tools should have that codified in their `access` configuration.",
        "remediation": "Edit the yml to include fully expose the models that your exposures depend on. This rule will only flag models that are not `public`, but best practices suggest you should also fully document and contracts these public models as well.\n\n```yml\nmodels:\n  - name: fct_model_6\n    description: very important OKR reporting model\n    access: public\n    config:\n      materialized: table\n      contract:\n        enforced: true\n    columns:\n      - name: id \n        description: the primary key of my OKR model\n        data_type: integer\n  - name: dim_model_7\n    description: excellent model\n    access: public\n```"
      }
    }
  },
  "Performance": {
    "rules": {
      "fct_chained_views_dependencies": {
        "name": "Chained View Dependencies",
        "description": "[See overriding variables section.",
        "example": "`table_1` depends on a chain of 4 views (`view_1`, `view_2`, `view_3`, and `view_4`).\n\n![dag of chain of 4 views, then a table](images/fct_chained_views_dependencies_dag_of_chain_of_4_views__then_.png){ width=700 }",
        "exception": "Not specified in documentation",
        "reason_to_flag": "You may experience a long runtime for a model when it is build on top of a long chain of \"non-physically-materialized\" models (views and ephemerals). In the example above, nothing is really computed until you get to `table_1`. At which point, it is going to run the query within `view_4`, which will then have to run the query within `view_3`, which will then have the run the query within `view_2`, which will then have to run the query within `view_1`. These will all be running at the same time, which creates a long runtime for `table_1`.",
        "remediation": "Follow dbt best practices to resolve chained view dependencies issues"
      },
      "fct_exposure_parents_materializations": {
        "name": "Exposure Parents Materializations",
        "description": "a `model` that does not use the `table` or `incremental` materialization\n\n**Example**\n\n![An example exposure with a table parent (fct_model_6) and an ephemeral parent (dim_model_7)](https://user-images.",
        "example": "![An example exposure with a table parent (fct_model_6) and an ephemeral parent (dim_model_7)](images/fct_exposure_parents_materializations_An_example_exposure_with_a_tab.png){ width=500 }\n\nIn this case, the parents of `exposure_1` are not both materialized as tables -- `dim_model_7` is ephemeral, while `fct_model_6` is a table. This model would return a record for the `dim_model_7 --> exposure_1` relationship.",
        "exception": "Not specified in documentation",
        "reason_to_flag": "Exposures should depend on the business logic you encoded into your dbt project (e.g. models or metrics) rather than raw untransformed sources. Additionally, models that are referenced by an exposure are likely to be used heavily in downstream systems, and therefore need to be performant when queried.",
        "remediation": "If you have a source parent of an exposure, you should incorporate that raw data into your project in some way, then update the exposure to point to that model.\n\nIf necessary, update the `materialized` configuration on the models returned in `fct_exposure_parents_materializations` to either `table` or `incremental`. This can be done in individual model files using a config block, or for groups of models in your `dbt_project.yml` file. See the docs on [model configurations](https://docs.getdbt.com/reference/model-configs) for more info!"
      }
    }
  }
}